{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 环境搭建\n",
    "- 安装pyenv做本地环境管理\n",
    "- 将本地目录设置为需要的python版本\n",
    "- 安装Langchain包"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 创建虚拟环境\n",
    "python -m venv myenv\n",
    "\n",
    "#### warning: donot use python 3.12. this notebook uses 3.11"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### python环境测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world!\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 依赖安装\n",
    "- 安装openai的api包\n",
    "- 或者使用Baichuan、ChatGLM这样的开源包"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "pip install openai langchain\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 激活虚拟环境\n",
    "myenv\\Scripts\\activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o:\\Documents\\langchain_AI_Agent\\myenv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 引入openai key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Install python-dotenv package:  \n",
    "   `pip install python-dotenv`\n",
    "\n",
    "2. Create a .env file in the root of your project and add your API key:  \n",
    "   `API_KEY=your_api_key_here`\n",
    "\n",
    "3. Add `.env` to your `.gitignore` file to ensure it doesn’t get committed to your repository.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 从环境变量中读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API_KEY: sk-proj-Wt0YV7MXuz5i8BX2BQAXT3BlbkFJjI7ooOvMiZI7ZwXIR03n\n",
      "API_PROXY: https://ai-yyds.com/v1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "API_PROXY = os.getenv(\"OPENAI_API_PROXY\")\n",
    "\n",
    "print(\"API_KEY:\", API_KEY)\n",
    "print(\"API_PROXY:\", API_PROXY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 运行前查看下安装情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip show openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip show langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### openai 官方SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-9Zm39vk4IDHzqKprnWFnf2BFqCH1h', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='你好，我是一个经过训练的AI助手，被设计用来回答问题、提供帮助和与用户交流。我拥有丰富的知识库，能够为您提供各种领域的信息和指导。如果您有任何问题，请随时问我，我会尽力为您提供帮助。希望能够和您愉快地交流和互动！', role='assistant', function_call=None, tool_calls=None))], created=1718313211, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=122, prompt_tokens=15, total_tokens=137))\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"API_KEY\"),\n",
    ")\n",
    "\n",
    "# Define the chat messages\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"介绍下你自己\"}\n",
    "]\n",
    "\n",
    "# Create a chat completion using the new API\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用langchain调用 openai\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "o:\\Documents\\langchain_tutorials\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "# use API_BASE if you are in China\n",
    "api_base = os.getenv(\"OPENAI_API_PROXY\")\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    temperature=0,\n",
    "    openai_api_key=api_key,\n",
    "    # openai_api_base=api_base\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 提示模板（PromptTemplate）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is a good name for a company that makes colorful socks?\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    " \n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What is a good name for a company that makes {product}?\",\n",
    ")\n",
    "\n",
    "print(prompt.format(product=\"colorful socks\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 起名大师"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是一个起名大师,请模仿示例起3个中国特色的名字,比如男孩经常被叫做狗蛋,女孩经常被叫做翠花\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n男孩: 龙飞、铁柱、小虎\\n女孩: 玉兰、梅香、小红梅'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#起名大师\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "import os\n",
    "\n",
    "# use API_BASE if you are in China\n",
    "api_base = os.getenv(\"API_BASE\")\n",
    "\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    temperature=0,\n",
    "    openai_api_key=api_key,\n",
    "    openai_api_base=api_base\n",
    "    )\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"你是一个起名大师,请模仿示例起3个{county}名字,比如男孩经常被叫做{boy},女孩经常被叫做{girl}\")\n",
    "message = prompt.format(county=\"中国特色的\",boy=\"狗蛋\",girl=\"翠花\")\n",
    "print(message)\n",
    "llm.invoke(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 格式化输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', 'bye']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "#自定义class，继承了BaseOutputParser\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "CommaSeparatedListOutputParser().parse(\"hi, bye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是一个起名大师,请模仿示例起3个具有美国男孩特色的名字,示例：男孩常用名sam,女孩常用名lucy。请返回以逗号分隔的列表形式。仅返回逗号分隔的列表，不要返回其他内容。\n",
      "\n",
      "\n",
      "jack, michael, jason\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['jack', ' michael', ' jason']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#起名大师，输出格式为一个数组\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "import os\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "#自定义类\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        print(text)\n",
    "        return text.strip().split(\",\")\n",
    "\n",
    "\n",
    "api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    temperature=0,\n",
    "    openai_api_key=api_key,\n",
    "    openai_api_base=api_base\n",
    "    )\n",
    "prompt = PromptTemplate.from_template(\"你是一个起名大师,请模仿示例起3个具有{county}特色的名字,示例：男孩常用名{boy},女孩常用名{girl}。请返回以逗号分隔的列表形式。仅返回逗号分隔的列表，不要返回其他内容。\")\n",
    "message = prompt.format(county=\"美国男孩\",boy=\"sam\",girl=\"lucy\")\n",
    "print(message)\n",
    "strs = llm.predict(message)\n",
    "CommaSeparatedListOutputParser().parse(strs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "openai_api_key = os.getenv(\"API_KEY\")\n",
    "if openai_api_key is None:\n",
    "    raise ValueError(\"API_KEY is not set\")\n",
    "\n",
    "chat = ChatOpenAI(api_key=openai_api_key, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a world class technical documentation writer.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "chain = prompt | chat\n",
    "\n",
    "chat.invoke(\"how can langsmith help with testing?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Langsmith is a powerful tool that can greatly assist in testing various aspects of software applications. Here are some ways in which Langsmith can help with testing:\\n\\n1. **Automated Testing**: Langsmith can be used to automate the testing process, making it faster and more efficient. You can write scripts in Langsmith to perform various tests, such as unit tests, integration tests, and end-to-end tests.\\n\\n2. **Performance Testing**: Langsmith can help in conducting performance tests to evaluate the speed, responsiveness, and stability of your application under different conditions. This can help identify potential bottlenecks and optimize the performance of the software.\\n\\n3. **Load Testing**: Langsmith can simulate a large number of users accessing your application simultaneously, helping to determine how well your application can handle peak loads. This can be crucial in ensuring that your application can perform well under heavy traffic.\\n\\n4. **API Testing**: Langsmith can be used to test APIs by sending requests and validating responses. This can help ensure that APIs are functioning correctly and returning the expected results.\\n\\n5. **Security Testing**: Langsmith can assist in conducting security tests to identify vulnerabilities in your application. By writing scripts to simulate various attack scenarios, you can assess the security posture of your software and take necessary measures to enhance security.\\n\\n6. **Regression Testing**: Langsmith can be used to automate regression tests, ensuring that new code changes do not introduce any unintended side effects or break existing functionality.\\n\\nOverall, Langsmith can streamline the testing process, improve test coverage, and help in delivering high-quality software products to end users.', response_metadata={'token_usage': {'completion_tokens': 318, 'prompt_tokens': 28, 'total_tokens': 346}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-95490fa4-a367-4233-a4d2-a4d16cbeae2f-0', usage_metadata={'input_tokens': 28, 'output_tokens': 318, 'total_tokens': 346})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\":\"how can langsmith help with testing?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
